# Background Sync & Incremental Optimization

## Overview

This document explains the **automatic background synchronization** and **incremental sync optimization** features.

## ğŸ• Background Cron Job (10-Minute Automatic Sync)

### Features

- âœ… **Automatic execution**: Starts automatically when server starts
- âœ… **10-minute interval**: Runs every 10 minutes
- âœ… **Smart filtering**: Only users not synced in the last 15+ minutes
- âœ… **Low priority**: Background sync messages added to queue with low priority (priority: 3)
- âœ… **Concurrent-safe**: Prevents multiple simultaneous executions

### How It Works

```
Server starts â†’ Cron starts â†’ Every 10 minutes:
  1. Find active users (valid token + not synced in 15+ minutes)
  2. Add to queue (priority: 3)
  3. Worker automatically processes
```

### Usage

Starts **automatically** when the server starts:

```bash
cd backend
yarn dev  # or in production: node dist/server.js
```

Console output:

```
ğŸš€ Server is running on http://localhost:4000/graphql
...
ğŸ• Starting user killmail background sync...
   ğŸ“… Interval: Every 10 minutes
   ğŸ“¦ Queue: esi_user_killmails_queue

âœ… User killmail cron started
```

On each execution:

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ• [25.12.2025 14:30:00] Running background sync...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   ğŸ“Š Found 3 user(s) to sync
   â³ John Doe (last: 20m ago)
   â³ Jane Smith (never)
   â³ Bob Wilson (last: 45m ago)

   âœ… Queued 3 user(s) in 125ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### Code Structure

**Service:** `/backend/src/services/user-killmail-cron.ts`

```typescript
export class UserKillmailCron {
  private intervalId: NodeJS.Timeout | null = null;
  private isRunning = false;

  async start() {
    /* Start */
  }
  stop() {
    /* Stop */
  }
  private async syncUsers() {
    /* Sync operation */
  }
  getStatus() {
    /* Status info */
  }
}

export const userKillmailCron = new UserKillmailCron();
```

**Integration:** `/backend/src/server.ts`

```typescript
import { userKillmailCron } from "./services/user-killmail-cron";

server.listen(port, () => {
  // ...
  userKillmailCron.start().catch((error) => {
    console.error("âŒ Failed to start user killmail cron:", error);
  });
});
```

## ğŸš€ Incremental Sync Optimization

### Problem

Previously, on each sync:

- **50 pages** (2500 killmails) were fetched
- **API call for each page** was made
- **Already existing killmails** were processed repeatedly
- **Unnecessary ESI rate limit** usage

### Solution: Incremental Sync

ESI API returns killmails in **reverse chronological order** (newest â†’ oldest). Using this feature:

1. **Save the last synced killmail ID** (`last_killmail_id`)
2. **In new sync** stop as soon as you see this ID
3. **Only fetch new killmails**

### Performance Improvement

| Scenario                               | Before   | After    | Improvement        |
| -------------------------------------- | -------- | -------- | ------------------ |
| **Initial sync**                       | 50 pages | 50 pages | Same               |
| **15 minutes later (1-2 killmails)**   | 50 pages | 1 page   | **50x faster**     |
| **Daily (5-10 killmails)**             | 50 pages | 1 page   | **50x faster**     |
| **Weekly (50+ killmails)**             | 50 pages | 2-3 pages| **~20x faster**    |

### How It Works

#### 1. Database Schema

```prisma
model User {
  // ...
  last_killmail_id       Int?      // Last synchronized killmail ID
  last_killmail_sync_at  DateTime? // Last sync time

  @@index([last_killmail_id])
  @@index([last_killmail_sync_at])
}
```

#### 2. Queue Message

```typescript
interface UserKillmailMessage {
  userId: number;
  characterId: number;
  // ...
  lastKillmailId?: number; // ğŸ”¥ New field
}
```

**Queue script:** `/backend/src/queues/queue-user-esi-killmails.ts`

```typescript
const message: UserKillmailMessage = {
  // ...
  lastKillmailId: user.last_killmail_id ?? undefined, // Include last ID
};
```

#### 3. Worker Logic

**Worker:** `/backend/src/workers/worker-esi-user-killmails.ts`

```typescript
await syncUserKillmailsFromESI(
  message,
  message.lastKillmailId // Pass last known ID
);
```

#### 4. CharacterService Optimization

**Service:** `/backend/src/services/character/character.service.ts`

```typescript
static async getCharacterKillmails(
  characterId: number,
  token: string,
  maxPages: number = 50,
  stopAtKillmailId?: number // ğŸ”¥ New parameter
): Promise<EsiKillmail[]> {
  for (let page = 1; page <= maxPages; page++) {
    const killmails = await fetchPage(page);

    // ğŸ”¥ Incremental sync optimization
    if (stopAtKillmailId) {
      const stopIndex = killmails.findIndex(
        km => km.killmail_id === stopAtKillmailId
      );

      if (stopIndex !== -1) {
        // Found last synced killmail - stop here!
        const newKillmails = killmails.slice(0, stopIndex);
        allKillmails.push(...newKillmails);
        console.log(`âœ… Found last synced ID: ${stopAtKillmailId}`);
        break; // ğŸ”¥ Stop early, don't fetch unnecessary pages
      }
    }

    allKillmails.push(...killmails);
  }
}
```

#### 5. Worker Output

**Initial sync (no lastKillmailId):**

```
ğŸ“¡ [John Doe] Fetching killmails from ESI (full sync)...
   ğŸ“„ Page 1: 50 killmails
   ğŸ“„ Page 2: 50 killmails
   ...
   ğŸ“„ Page 15: 50 killmails
   âœ“ Last page (42 < 50)
   âœ… Total: 742 killmails from ESI
```

**Second sync (lastKillmailId: 123456789):**

```
ğŸ“¡ [John Doe] Fetching NEW killmails from ESI (incremental sync)...
   ğŸ” Will stop at killmail ID: 123456789
   ğŸ“„ Page 1: 50 killmails
   âœ… Incremental sync: Found last synced killmail (ID: 123456789)
   â­ï¸  Stopping at page 1 - fetched 3 new killmails
   âœ… Total: 3 killmails from ESI
```

**Result:** Only **1 page** fetched instead of 50 pages!

#### 6. Database Update

```typescript
// Worker saves highest killmail ID
if (killmailList.length > 0) {
  const latestKillmailId = Math.max(
    ...killmailList.map((km) => km.killmail_id)
  );

  await prisma.user.update({
    where: { id: message.userId },
    data: {
      last_killmail_sync_at: new Date(),
      last_killmail_id: latestKillmailId, // ğŸ”¥ Save for next sync
    },
  });
}
```

## ğŸ“Š Working Together

### Complete Workflow

```
1. Server starts
   â†“
2. Cron job starts (every 10 minutes)
   â†“
3. Cron runs:
   - Find active users
   - Include last_killmail_id
   - Add to queue (priority: 3)
   â†“
4. Worker processes:
   - If lastKillmailId exists, perform incremental sync
   - Fetch only new killmails
   - Save to database
   - Update last_killmail_id
   â†“
5. Next cron execution:
   - Use updated last_killmail_id
   - Much faster sync
```

### Advantages

| Feature                    | Benefit                                  |
| -------------------------- | ---------------------------------------- |
| **Automatic sync**         | Up-to-date data without user action      |
| **10-minute interval**     | Frequent enough but doesn't spam API     |
| **15-minute buffer**       | Prevents unnecessary re-sync             |
| **Incremental sync**       | 50x fewer API calls                      |
| **Rate limit friendly**    | Doesn't exceed ESI limits                |
| **Background priority**    | Manual syncs have priority               |
| **Concurrent-safe**        | No collision risk                        |

## ğŸ§ª Testing

### 1. Start Server

```bash
cd backend
yarn dev
```

You'll see in console:

```
ğŸ• Starting user killmail background sync...
âœ… User killmail cron started
```

### 2. Start Worker

```bash
cd backend
yarn worker:user-killmails
```

### 3. Watch Initial Sync

Initial sync: **Full sync** (no lastKillmailId)

```
ğŸ“¡ [John Doe] Fetching killmails from ESI (full sync)...
   ğŸ“„ Page 1: 50 killmails
   ğŸ“„ Page 2: 50 killmails
   ...
```

### 4. Wait 10 Minutes

Cron will run automatically:

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ• [25.12.2025 14:40:00] Running background sync...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   ğŸ“Š Found 1 user(s) to sync
   â³ John Doe (last: 10m ago)
```

### 5. Watch Second Sync

Second sync: **Incremental sync** (lastKillmailId exists)

```
ğŸ“¡ [John Doe] Fetching NEW killmails from ESI (incremental sync)...
   ğŸ” Will stop at killmail ID: 123456789
   ğŸ“„ Page 1: 50 killmails
   âœ… Incremental sync: Found last synced killmail (ID: 123456789)
   â­ï¸  Stopping at page 1 - fetched 2 new killmails
```

**Result:** 50 pages â†’ 1 page = **50x faster/tmp/postgresql_en.md /root/killreport/backend/src/docs/POSTGRESQL_QUERY_CACHE_ANALYSIS.MD* ğŸš€

## ğŸ“ Important Notes

### Cron Job

- âœ… **Starts automatically**: When server starts
- âœ… **Graceful shutdown**: Stops properly when process is killed
- âœ… **Error handling**: Logs errors, doesn't crash
- âœ… **Status checking**: Check status with `userKillmailCron.getStatus()`

### Incremental Sync

- âœ… **Initial sync always full**: No lastKillmailId yet
- âœ… **Trust ESI order**: Reverse chronological order guaranteed
- âœ… **Edge case handling**: Full sync if killmail not found
- âœ… **Database index**: last_killmail_id indexed for performance

### Rate Limiting

- âœ… **ESI limit: 150 req/sec** - our usage is far below
- âœ… **Background priority: 3** - manual syncs have priority: 5
- âœ… **Worker prefetch: 1** - processes 1 user at a time
- âœ… **Page delay: 100ms** - wait between pages

## ğŸ¯ Conclusion

With these two features:

1. **Automatic sync**: Users get synced every 10 minutes without doing anything
2. **50x performance**: Much faster with incremental sync
3. **Rate limit friendly**: We don't exceed ESI limits
4. **User experience**: Real-time data, no manual sync needed

**Both user experience and system performance dramatically improved/tmp/postgresql_en.md /root/killreport/backend/src/docs/POSTGRESQL_QUERY_CACHE_ANALYSIS.MD* ğŸ‰
